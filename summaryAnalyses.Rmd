---
title: "SummaryAnalyses"
author: "Maria Eckstein"
date: "October 24, 2017"
output: html_document
---

# Get data

```{r Set parameters load packages etc.}

# Load packages
source("read_in_data.R"); source("plot_each_trial.R"); source("get_dir.R"); source("plot_summary.R")
library("ggplot2"); library("plyr"); library("reshape"); library("gridExtra")
theme_set(theme_bw())

# What's the base directory of that data?
base_dir = "C:/Users/maria/MEGAsync/Berkeley/LEARN/data"
sum_plot_dir = file.path(base_dir, "plots")
if (!dir.exists(sum_plot_dir)) {
  dir.create(sum_plot_dir)
}

# What data do I have?
agents = seq(0, 2)
envs = seq(0, 15)

# Should plots be saved?
gg_save  = T
analyze_all_trials = F
analyze_my_algo = F
analyze_all_algos = T

# Which data should be plotted?
which_data = list()
which_data$n_options_per_level = "[5, 5, 5, 5, 5]"
which_data$n_levels = 5
which_data$option_length = 2
which_data$alpha = "0.3"
which_data$n_lambda = "0.3"
which_data$gamma = "0.9"
which_data$epsilon = "0.2"
which_data$distraction = "0.1"
which_data$env_id = envs[1]
which_data$agent_id = envs[1]
which_data$learning_signal = "novelty"
which_data$hier = "hierarchical"
```

```{r Analyze environments trialwise for all agents}

if (analyze_all_trials) {
  for (env_id in envs) {
    for (hier in c("hierarchical", "flat")) {
      for (learning_signal in c("novelty", "reward")) {
        
        print(c(env_id, hier, learning_signal))
        
        # Define data to be loaded
        which_data$env_id = env_id
        which_data$hier = hier
        which_data$learning_signal = learning_signal
        
        # Load data and attach to dataframe containing all data
        all_dat = read_in_data(base_dir, which_data)
        plot_dir = get_dir(base_dir, which_data)$plot_dir
        plot_each_trial(all_dat, gg_save, plot_dir)
      }
    }
  }
}
```

```{r Analyze my HN agent in detail in one specific environment}

if (analyze_my_algo) {
  
  # Load data: one environment, 10 agents
  algo_n = data.frame()
  algo_v = data.frame()
  algo_theta = data.frame()
  rules = data.frame()
  
  which_data$hier = "hierarchical"
  which_data$learning_signal = "novelty"
  which_data$env_id = 7

  for (agent_id in seq(0, 10)) {
    which_data$agent_id = agent_id
    all_dat = read_in_data(base_dir, which_data)
    algo_n = rbind(algo_n, all_dat$n_hist)
    algo_v = rbind(algo_v, all_dat$v_hist)
    algo_theta = rbind(algo_theta, all_dat$theta_hist)
    rules = rbind(rules, all_dat$rules)
  }

  # Prepare data
  algo_n$action = factor(algo_n$action)
  algo_v$action = factor(algo_v$action)
  algo_theta_sum = ddply(subset(algo_theta, trial == max(algo_theta$trial)),
                         .(level, option, action, feature),
                         summarize,
                         value = mean(value, na.rm = T))
  
  # Results
  ## Rules
  rules
  
  ## Novelty over time
  gg_summary_novelty = ggplot(algo_n, aes(trial, value, group = action, color = action, fill = action)) +
    stat_summary(fun.data = "mean_se", geom = "smooth") +
    labs(x = "Trial", y = "Novelty", color = "Action", fill = "Action") +
    facet_grid(~ factor(level, levels = unique(algo_n$level), labels = paste("Level", unique(algo_n$level))))
  
  ## Value over time
  gg_summary_value = gg_summary_novelty + labs(y = "Curiosity")
  gg_summary_value$data = algo_v
  
  ## Final option policies
  gg_theta = ggplot(algo_theta_sum, aes(action, feature)) +
    geom_tile(aes(fill = value), color = "white") +
    geom_text(aes(label = round(value, 2)), size = 1.5) +
    scale_fill_gradient(low = "white", high = "red", limits = c(min(algo_theta$value), max(algo_theta$value))) +
    labs(x = "Action ID", y = "Feature") +
    theme(legend.position = "none") +
    facet_wrap(factor(level, levels = sort(unique(algo_theta$level)), labels = paste("Level", sort(unique(algo_theta$level)))) ~
                 factor(option, levels = sort(unique(algo_theta$option)), labels = paste("Option", sort(unique(algo_theta$option)))))
  
  # Save results
  if (gg_save) {
    identifier = paste(which_data$n_options_per_level, "_e", which_data$env_id, ".png", sep = "")
    file_name = paste("gg_summary_novelty_", identifier, sep = "")
    ggsave(file.path(sum_plot_dir, file_name), gg_summary_novelty, width = 10, height = 2)
    file_name = paste("gg_summary_value_", identifier, sep = "")
    ggsave(file.path(sum_plot_dir, file_name), gg_summary_value, width = 10, height = 2)
    file_name = paste("gg_theta_", identifier, sep = "")
    ggsave(file.path(sum_plot_dir, file_name), gg_theta, width = which_data$n_levels, height = 5)
  }
  
  # RMSE of option policies}
  # Get optimal policies
  # Need rules and gamma
  
  # Subtract agent's values from optimal values in each trial
  
  # Plot
}
```

# Compare agents

```{r Read in data from all algos}
if (analyze_all_algos) {
  
  # Set up empty dataframes that will contain all the data
  n_hist = data.frame()
  v_hist = data.frame()
  state_hist = data.frame()
  option_hist = data.frame()
  theta_hist = data.frame()
  event_hist = data.frame()
  rules = data.frame()

  for (env_id in envs) {
    
    # Define data to be loaded
    which_data$hier = "hierarchical"
    which_data$learning_signal = "novelty"
    which_data$env_id = env_id
    all_dat = read_in_data(base_dir, which_data)
    rules = rbind(rules, all_dat$rules)
    
    for (hier in c("hierarchical", "flat")) {
      for (learning_signal in c("novelty", "reward")) {
        for (agent_id in agents) {
          
          print(c(hier, learning_signal, agent_id, env_id))
          which_data$hier = hier
          which_data$learning_signal = learning_signal
          which_data$agent_id = agent_id
          
          # Load data and attach to dataframe containing all data
          all_dat = read_in_data(base_dir, which_data)
          event_hist = rbind(event_hist, all_dat$event_hist)
          v_hist = rbind(v_hist, all_dat$v_hist)
          
          # n_hist = rbind(n_hist, all_dat$n_hist)
          # theta_hist = rbind(theta_hist, all_dat$theta_hist)
          # state_hist = rbind(state_hist, all_dat$state_hist)
          # option_hist = rbind(option_hist, all_dat$option_hist)
  
        }
      }
    }
  }

  # Prepare data
  event_hist = subset(event_hist, trial < 300)
  event_hist$env_id = factor(event_hist$env_id)
  event_hist$agent_id = factor(event_hist$agent_id)
  event_hist$option_length = which_data$option_length ** (event_hist$level + 1)
  event_hist$algorithm = with(event_hist, paste(hier, learning_signal))
  
  v_hist = subset(v_hist, trial < 300)
  v_hist$env_id = factor(v_hist$env_id)
  v_hist$agent_id = factor(v_hist$agent_id)
  v_hist$level = factor(v_hist$level)
  
  ## Number of events produced over time
  bin_size = 10
  event_hist$bin = NA
  for (bin in seq(0, max(event_hist$trial), bin_size)) {
    event_hist[event_hist$trial >= bin,]$bin = bin
  }
  event_hist_sum = ddply(event_hist,
        .(env_id, hier, learning_signal, agent_id, bin, level, option_length),
        summarize,
        n_events = sum(value))
  n_actions = length(unique(event_hist$action))
  event_hist_sum$frac_events = event_hist_sum$n_events * (event_hist_sum$option_length * n_actions) / 100
  event_hist_sum$level = factor(event_hist_sum$level)
  
  # Plot
  ## Option values over time
  gg_v = ggplot(v_hist, aes(trial, value, color = level)) +
    stat_summary(fun.y = "mean", geom = "line") +
    labs(x = "Trial", y = "Option / action value", color = "Level") +
    facet_grid(hier ~ learning_signal)
  
  ## Number of events discovered
  gg_n_disc_events = ggplot(event_hist, aes(trial, n_disc_events, color = algorithm)) +
    stat_summary(fun.y = "mean", geom = "line") +
    labs(x = "Trial", y = "# events discovered", color = "Algorithm")
  gg_n_disc_events_big = gg_n_disc_events + facet_wrap(~ paste("Env.", env_id))
  
  # Number of events elicited
  gg_n_events = ggplot(subset(event_hist_sum, level != 0), aes(bin, n_events, color = level)) +
    # stat_summary(fun.data = "mean_se", geom = "pointrange") +
    stat_summary(fun.y = "mean", geom = "line") +
    labs(x = "Trial", y = paste("# of events per", bin_size, "trials"), color = "Level") +
    coord_cartesian(y = c(0, bin_size)) +
    facet_grid(hier ~ learning_signal)
  
  gg_frac_events = gg_n_events +
    aes(bin, frac_events) +
    coord_cartesian(y = c(0, 1)) +
    labs(x = "Trial", y = "# of events rel. to execution time", color = "Level")
  
  ## Number of times each action is executed (depending on how many options is it part of)
  action_centrality = expand.grid(action = unique(event_hist$action), level = unique(event_hist$level))
  
  ## Number of perseverative actions

  
  if (gg_save) {
    identifier = paste(which_data$n_options_per_level, ".png", sep = "")
    ggsave(file.path(sum_plot_dir, paste("gg_n_disc_events_", identifier, sep = "")), gg_n_disc_events, width = 4, height = 2, device = "jpeg")
    ggsave(file.path(sum_plot_dir, paste("gg_n_disc_events_big_", identifier, sep = "")), gg_n_disc_events_big, width = 6, height = 5, device = "jpeg")
    ggsave(file.path(sum_plot_dir, paste("gg_v_", identifier, sep = "")), gg_v, width = 5, height = 3, device = "jpeg")
    ggsave(file.path(sum_plot_dir, paste("gg_n_events_", identifier, sep = "")), gg_n_events, width = 5, height = 4, device = "jpeg")
    ggsave(file.path(sum_plot_dir, paste("gg_frac_events_", identifier, sep = "")), gg_frac_events, width = 5, height = 3, device = "jpeg")
  }
  
}
```

```{r}
```